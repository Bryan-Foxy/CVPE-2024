{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected 42 anomalies:\n",
      "Anomaly 1: Area = 286.0 pixels, Center = (506.5, 570.7)\n",
      "Anomaly 2: Area = 137.0 pixels, Center = (484.2, 795.3)\n",
      "Anomaly 3: Area = 256.0 pixels, Center = (378.4, 546.0)\n",
      "Anomaly 4: Area = 254.0 pixels, Center = (542.5, 645.9)\n",
      "Anomaly 5: Area = 219.0 pixels, Center = (407.5, 564.8)\n",
      "Anomaly 6: Area = 217.0 pixels, Center = (370.0, 410.4)\n",
      "Anomaly 7: Area = 104.0 pixels, Center = (425.6, 404.7)\n",
      "Anomaly 8: Area = 143.0 pixels, Center = (560.5, 674.6)\n",
      "Anomaly 9: Area = 72.0 pixels, Center = (397.5, 677.7)\n",
      "Anomaly 10: Area = 152.0 pixels, Center = (396.8, 399.7)\n",
      "Anomaly 11: Area = 163.0 pixels, Center = (372.9, 663.6)\n",
      "Anomaly 12: Area = 142.0 pixels, Center = (477.0, 710.3)\n",
      "Anomaly 13: Area = 137.0 pixels, Center = (282.9, 383.4)\n",
      "Anomaly 14: Area = 51.0 pixels, Center = (453.4, 439.0)\n",
      "Anomaly 15: Area = 222.0 pixels, Center = (339.4, 672.4)\n",
      "Anomaly 16: Area = 282.0 pixels, Center = (471.8, 590.8)\n",
      "Anomaly 17: Area = 90.0 pixels, Center = (475.4, 762.9)\n",
      "Anomaly 18: Area = 160.0 pixels, Center = (407.7, 174.6)\n",
      "Anomaly 19: Area = 190.0 pixels, Center = (512.0, 613.6)\n",
      "Anomaly 20: Area = 251.0 pixels, Center = (578.5, 71.4)\n",
      "Anomaly 21: Area = 185.0 pixels, Center = (431.8, 448.1)\n",
      "Anomaly 22: Area = 61.0 pixels, Center = (436.8, 293.6)\n",
      "Anomaly 23: Area = 74.0 pixels, Center = (928.5, 348.9)\n",
      "Anomaly 24: Area = 82.0 pixels, Center = (429.1, 317.0)\n",
      "Anomaly 25: Area = 92.0 pixels, Center = (258.4, 240.6)\n",
      "Anomaly 26: Area = 87.0 pixels, Center = (261.7, 338.8)\n",
      "Anomaly 27: Area = 204.0 pixels, Center = (506.3, 527.2)\n",
      "Anomaly 28: Area = 114.0 pixels, Center = (447.2, 396.9)\n",
      "Anomaly 29: Area = 24.0 pixels, Center = (17.5, 454.0)\n",
      "Anomaly 30: Area = 26.0 pixels, Center = (17.7, 454.2)\n",
      "Anomaly 31: Area = 19.0 pixels, Center = (15.4, 641.9)\n",
      "Anomaly 32: Area = 55.0 pixels, Center = (310.1, 342.8)\n",
      "Anomaly 33: Area = 86.0 pixels, Center = (564.6, 117.0)\n",
      "Anomaly 34: Area = 74.0 pixels, Center = (592.2, 248.0)\n",
      "Anomaly 35: Area = 68.0 pixels, Center = (915.6, 387.6)\n",
      "Anomaly 36: Area = 250.0 pixels, Center = (208.5, 773.9)\n",
      "Anomaly 37: Area = 207.0 pixels, Center = (354.5, 526.5)\n",
      "Anomaly 38: Area = 154.0 pixels, Center = (225.2, 160.5)\n",
      "Anomaly 39: Area = 98.0 pixels, Center = (392.0, 589.7)\n",
      "Anomaly 40: Area = 70.0 pixels, Center = (454.2, 730.0)\n",
      "Anomaly 41: Area = 9.0 pixels, Center = (14.0, 287.0)\n",
      "Anomaly 42: Area = 14.0 pixels, Center = (41.3, 287.5)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator\n",
    "from skimage.transform import resize  # Pour redimensionner les masques\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def initialize_sam(checkpoint_path, device='cpu'):\n",
    "    \"\"\"Initialize SAM model with optimized parameters.\"\"\"\n",
    "    sam = sam_model_registry[\"vit_h\"](checkpoint=checkpoint_path)\n",
    "    sam.to(device=device)\n",
    "    \n",
    "    # Optimized parameters for small anomaly detection\n",
    "    mask_generator = SamAutomaticMaskGenerator(\n",
    "        model=sam,\n",
    "        points_per_side=51,\n",
    "        pred_iou_thresh=0.88,  # Increased for better precision\n",
    "        stability_score_thresh=0.90,  # Increased for more stable masks\n",
    "        crop_n_layers=1,\n",
    "        crop_n_points_downscale_factor=2,  # Increased for speed\n",
    "        min_mask_region_area=16,  # Reduced to catch smaller anomalies\n",
    "        output_mode=\"binary_mask\"\n",
    "    )\n",
    "    return mask_generator\n",
    "\n",
    "\n",
    "def process_image(image_path, target_size=(1024, 1024)):\n",
    "    \"\"\"Load and preprocess image with efficient resizing.\"\"\"\n",
    "    with Image.open(image_path).convert('RGB') as img:\n",
    "        img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n",
    "        return np.array(img_resized).astype(np.float32), img\n",
    "\n",
    "\n",
    "def analyze_regions(masks, threshold=300):\n",
    "    \"\"\"Analyze regions with optimized filtering.\"\"\"\n",
    "    regions = []\n",
    "    for idx, mask in enumerate(masks):\n",
    "        if mask['area'] < threshold:  # Only process small regions\n",
    "            y_indices, x_indices = np.where(mask['segmentation'])\n",
    "            if len(x_indices) > 0 and len(y_indices) > 0:\n",
    "                centroid = (np.mean(x_indices), np.mean(y_indices))\n",
    "                regions.append({\n",
    "                    'id': idx,\n",
    "                    'area_pixels': mask['area'],\n",
    "                    'centroid': centroid,\n",
    "                    'mask': mask['segmentation']\n",
    "                })\n",
    "    return regions\n",
    "\n",
    "\n",
    "def visualize_results(original_image, regions, save_path=None):\n",
    "    \"\"\"Create and save scientific visualization with resized masks.\"\"\"\n",
    "    original_size = original_image.size[::-1]  # (height, width)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5), dpi=150)\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(original_image)\n",
    "    axes[0].set_title(f'Original\\n({len(regions)} anomalies detected)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Create mask visualization\n",
    "    mask_overlay = np.zeros((*original_size, 4))  # Adjusted for the original size\n",
    "    red_color = np.array([1, 0, 0, 0.7])  # Red with 0.7 opacity\n",
    "    \n",
    "    for region in regions:\n",
    "        # Resize the mask to the original image size\n",
    "        resized_mask = resize(region['mask'], original_size, mode='constant', preserve_range=True).astype(bool)\n",
    "        mask_overlay[resized_mask] = red_color\n",
    "    \n",
    "    # Mask only\n",
    "    axes[1].imshow(mask_overlay)\n",
    "    axes[1].set_title('Detected Anomalies')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Overlay\n",
    "    axes[2].imshow(original_image)\n",
    "    axes[2].imshow(mask_overlay)\n",
    "    axes[2].set_title('Overlay')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Paths\n",
    "    sam_checkpoint = \"/Users/armandbryan/Documents/challenges/Computer Vision Projects Expo 2024/models/sam_vit_h_4b8939.pth\"\n",
    "    image_path = '/Users/armandbryan/Documents/challenges/Computer Vision Projects Expo 2024/datasets/aptos2019-blindness-detection/test_images/0a2b5e1a0be8.png'\n",
    "    \n",
    "    output_dir = 'anomaly_detection_results'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    mask_generator = initialize_sam(sam_checkpoint)\n",
    "    \n",
    "   \n",
    "    img_array, original_image = process_image(image_path)\n",
    "    masks = mask_generator.generate(img_array)\n",
    "    \n",
    "    # Analyze regions\n",
    "    regions = analyze_regions(masks)\n",
    "    \n",
    "    # Save results\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    save_path = os.path.join(output_dir, f'anomaly_detection_{timestamp}.png')\n",
    "    \n",
    "    # Visualize and save results\n",
    "    visualize_results(original_image, regions, save_path)\n",
    "    \n",
    "    # Print analysis\n",
    "    print(f\"\\nDetected {len(regions)} anomalies:\")\n",
    "    for i, region in enumerate(regions):\n",
    "        print(f\"Anomaly {i+1}: Area = {region['area_pixels']:.1f} pixels, \"\n",
    "              f\"Center = ({region['centroid'][0]:.1f}, {region['centroid'][1]:.1f})\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
